library(stringr)
library(maps)
library(mapdata)
library(ggmap)
library(maptools)
library(rgdal)
library(RColorBrewer)
library(lattice)
library(spdep)
#  libraries
library(sp)
library(ggplot2)
library(devtools)
library(dplyr)
library(stringr)
library(maps)
library(mapdata)
library(ggmap)
library(maptools)
library(rgdal)
library(RColorBrewer)
library(lattice)
library(spdep)
setwd("/Users/y.holtz/Desktop/ABDEL_DATA")
setwd("~/Desktop/ABDEL_DATA")
#  libraries
library(sp)
library(ggplot2)
library(devtools)
library(dplyr)
library(stringr)
library(maps)
library(mapdata)
library(ggmap)
library(maptools)
library(rgdal)
library(RColorBrewer)
library(lattice)
library(spdep)
setwd("~/Desktop/ABDEL_DATA")
d1 <- read.table("UKB.geowebsite.individual_level.polygenic_scores.100PCs.10kref.REVISION.csv")
d1 <- read.table("UKB.geowebsite.individual_level.polygenic_scores.100PCs.10kref.REVISION.csv", header=T)
d1 <- read.table("UKB.geowebsite.individual_level.polygenic_scores.100PCs.10kref.REVISION.csv", header=T, sep=",")
d1 <- read.table("UKB.geowebsite.individual_level.polygenic_scores.100PCs.10kref.REVISION.csv", header=T, sep=",", nrows=100)
head(d1)
#
d2 <- read.table("UKB.geowebsite.local_authority_level.polygenic_scores.100PCs.10kref.REVISION.csv", header=T, sep=",", nrows=100)
head(d2)
colnames(d1)
colnames(d2)
# Lat-Long + PCs + traits + traits.residual
d1 <- read.table("UKB.geowebsite.individual_level.polygenic_scores.100PCs.10kref.REVISION.csv", header=T, sep=",", nrows=100)
head(d1)
# Load map data
load("~/Desktop/UKB_geo_application/DATA/Map_data.Rdata")
ls()
plot(GBR_dist.bng)
# Lat-Long + PCs + traits + traits.residual
input <- read.table("UKB.geowebsite.individual_level.polygenic_scores.100PCs.10kref.REVISION.csv", header=T, sep=",", nrows=100)
input=na.omit(input)
# Load map data
load("~/Desktop/UKB_geo_application/DATA/Map_data.Rdata")
output=getwd()
compute_shape_sumstat = function(input, output){
##############################
# ENVIRONMENT
##############################
# libraries
library(sp)
library(devtools)
library(dplyr)
library(stringr)
library(maps)
library(mapdata)
library(rgdal)
library(lattice)
library(spdep)
library(rgeos)
library(cartogram)
incProgress(0.1, detail = "Start linking with regions")
################################################################
# PART X - LINK SPATIAL / INDIVIDUAL
################################################################
#turn into SpatialObject
coordinates(input) <- c("longitude","latitude")
# assign projection to UKB
bng = '+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +datum=OSGB36 +units=m +no_defs'
proj4string(input) <- bng
# ----------- REGION LARGE ---------------------------
# aggregate polygenic scores, PCs, and residuals by each UK region of the initial shape file.
GBR_dist.UKB.over <- over(GBR_dist.bng, input, fn = mean)
# I need to add the number of person per region!
GBR_dist.UKB.over$nb_people <- over(GBR_dist.bng, input, fn = length)[,1]
# clean format + add the geolabel column + use the good projection
GBR_region = SpatialPolygonsDataFrame(GBR_dist.bng, data=GBR_dist.UKB.over)
GBR_region@data$geo_label = GBR_dist.bng@data$geo_label
GBR_region= spTransform(GBR_region, CRS("+proj=longlat +datum=WGS84 +no_defs"))
incProgress(0.1, detail = "Aggregation to region OK")
# ----------- HEXAGONE---------------------------
# aggregate polygenic scores, PCs, and residuals by each UK region of the initial shape file.
UKB_hexa.bng.over <- over(UKB_hexa.bng, input, fn = mean)
# I need to add the number of person per region!
UKB_hexa.bng.over$nb_people <- over(UKB_hexa.bng, input, fn = length)[,1]
# clean format + add the geolabel column + use the good projection
GBR_hexa = SpatialPolygonsDataFrame(UKB_hexa.bng, data=UKB_hexa.bng.over)
GBR_hexa@data$geo_label = UKB_hexa.bng@data$LAD12NM
GBR_hexa = spTransform(GBR_hexa, CRS("+proj=longlat +datum=WGS84 +no_defs"))
incProgress(0.1, detail = "Aggregation to hexagone OK")
################################################################
# PART X - CARTOGRAM CREATION
################################################################
# This part is going to create the same object, but transforming the shapes proportionnaly of the number of people into them
# ----------- REGION LARGE ---------------------------
GBR_region_cartogram = cartogram(GBR_region, "nb_people", itermax=1)
incProgress(0.1, detail = "Cartogram region OK")
# ----------- HEXAGONE ---------------------------
GBR_hexa_cartogram = cartogram(GBR_hexa, "nb_people", itermax=1)
incProgress(0.1, detail = "Cartogram hexagone OK")
################################################################
# PART X - SAVE OBJECTS
################################################################
# Just return the objects if this is done on user data
return( list(GBR_region, GBR_region_cartogram, GBR_hexa, GBR_hexa_cartogram) )
}
compute_shape_sumstat = function(input, output){
##############################
# ENVIRONMENT
##############################
# libraries
library(sp)
library(devtools)
library(dplyr)
library(stringr)
library(maps)
library(mapdata)
library(rgdal)
library(lattice)
library(spdep)
library(rgeos)
library(cartogram)
incProgress(0.1, detail = "Start linking with regions")
################################################################
# PART X - LINK SPATIAL / INDIVIDUAL
################################################################
#turn into SpatialObject
coordinates(input) <- c("longitude","latitude")
# assign projection to UKB
bng = '+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +datum=OSGB36 +units=m +no_defs'
proj4string(input) <- bng
# ----------- REGION LARGE ---------------------------
# aggregate polygenic scores, PCs, and residuals by each UK region of the initial shape file.
GBR_dist.UKB.over <- over(GBR_dist.bng, input, fn = mean)
# I need to add the number of person per region!
GBR_dist.UKB.over$nb_people <- over(GBR_dist.bng, input, fn = length)[,1]
# clean format + add the geolabel column + use the good projection
GBR_region = SpatialPolygonsDataFrame(GBR_dist.bng, data=GBR_dist.UKB.over)
GBR_region@data$geo_label = GBR_dist.bng@data$geo_label
GBR_region= spTransform(GBR_region, CRS("+proj=longlat +datum=WGS84 +no_defs"))
incProgress(0.1, detail = "Aggregation to region OK")
# ----------- HEXAGONE---------------------------
# aggregate polygenic scores, PCs, and residuals by each UK region of the initial shape file.
UKB_hexa.bng.over <- over(UKB_hexa.bng, input, fn = mean)
# I need to add the number of person per region!
UKB_hexa.bng.over$nb_people <- over(UKB_hexa.bng, input, fn = length)[,1]
# clean format + add the geolabel column + use the good projection
GBR_hexa = SpatialPolygonsDataFrame(UKB_hexa.bng, data=UKB_hexa.bng.over)
GBR_hexa@data$geo_label = UKB_hexa.bng@data$LAD12NM
GBR_hexa = spTransform(GBR_hexa, CRS("+proj=longlat +datum=WGS84 +no_defs"))
incProgress(0.1, detail = "Aggregation to hexagone OK")
################################################################
# PART X - CARTOGRAM CREATION
################################################################
# This part is going to create the same object, but transforming the shapes proportionnaly of the number of people into them
# ----------- REGION LARGE ---------------------------
GBR_region_cartogram = cartogram(GBR_region, "nb_people", itermax=1)
incProgress(0.1, detail = "Cartogram region OK")
# ----------- HEXAGONE ---------------------------
GBR_hexa_cartogram = cartogram(GBR_hexa, "nb_people", itermax=1)
incProgress(0.1, detail = "Cartogram hexagone OK")
################################################################
# PART X - SAVE OBJECTS
################################################################
# Just return the objects if this is done on user data
return( list(GBR_region, GBR_region_cartogram, GBR_hexa, GBR_hexa_cartogram) )
}
compute_shape_sumstat(input,output)
# libraries
library(sp)
library(devtools)
library(dplyr)
library(stringr)
library(maps)
library(mapdata)
library(rgdal)
library(lattice)
library(spdep)
library(rgeos)
library(cartogram)
compute_shape_sumstat(input,output)
# libraries
library(sp)
library(devtools)
library(dplyr)
library(stringr)
library(maps)
library(mapdata)
library(rgdal)
library(lattice)
library(spdep)
library(rgeos)
library(cartogram)
#turn into SpatialObject
coordinates(input) <- c("longitude","latitude")
# assign projection to UKB
bng = '+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +datum=OSGB36 +units=m +no_defs'
proj4string(input) <- bng
# aggregate polygenic scores, PCs, and residuals by each UK region of the initial shape file.
GBR_dist.UKB.over <- over(GBR_dist.bng, input, fn = mean)
# I need to add the number of person per region!
GBR_dist.UKB.over$nb_people <- over(GBR_dist.bng, input, fn = length)[,1]
# clean format + add the geolabel column + use the good projection
GBR_region = SpatialPolygonsDataFrame(GBR_dist.bng, data=GBR_dist.UKB.over)
GBR_region@data$geo_label = GBR_dist.bng@data$geo_label
GBR_region= spTransform(GBR_region, CRS("+proj=longlat +datum=WGS84 +no_defs"))
# aggregate polygenic scores, PCs, and residuals by each UK region of the initial shape file.
UKB_hexa.bng.over <- over(UKB_hexa.bng, input, fn = mean)
# I need to add the number of person per region!
UKB_hexa.bng.over$nb_people <- over(UKB_hexa.bng, input, fn = length)[,1]
# clean format + add the geolabel column + use the good projection
GBR_hexa = SpatialPolygonsDataFrame(UKB_hexa.bng, data=UKB_hexa.bng.over)
GBR_hexa@data$geo_label = UKB_hexa.bng@data$LAD12NM
GBR_hexa = spTransform(GBR_hexa, CRS("+proj=longlat +datum=WGS84 +no_defs"))
# ----------- REGION LARGE ---------------------------
GBR_region_cartogram = cartogram(GBR_region, "nb_people", itermax=1)
incProgress(0.1, detail = "Cartogram region OK")
# ----------- HEXAGONE ---------------------------
GBR_hexa_cartogram = cartogram(GBR_hexa, "nb_people", itermax=1)
# Just return the objects if this is done on user data
return( list(GBR_region, GBR_region_cartogram, GBR_hexa, GBR_hexa_cartogram) )
GBR_region_cartogram
GBR_region_cartogram@data
# Lat-Long + PCs + traits + traits.residual
input <- read.table("UKB.geowebsite.individual_level.polygenic_scores.100PCs.10kref.REVISION.csv", header=T, sep=",")
input=na.omit(input)
# Load map data
load("~/Desktop/UKB_geo_application/DATA/Map_data.Rdata")
output=getwd()
#turn into SpatialObject
coordinates(input) <- c("longitude","latitude")
# assign projection to UKB
bng = '+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +datum=OSGB36 +units=m +no_defs'
proj4string(input) <- bng
# aggregate polygenic scores, PCs, and residuals by each UK region of the initial shape file.
GBR_dist.UKB.over <- over(GBR_dist.bng, input, fn = mean)
# I need to add the number of person per region!
GBR_dist.UKB.over$nb_people <- over(GBR_dist.bng, input, fn = length)[,1]
# clean format + add the geolabel column + use the good projection
GBR_region = SpatialPolygonsDataFrame(GBR_dist.bng, data=GBR_dist.UKB.over)
GBR_region@data$geo_label = GBR_dist.bng@data$geo_label
GBR_region= spTransform(GBR_region, CRS("+proj=longlat +datum=WGS84 +no_defs"))
# aggregate polygenic scores, PCs, and residuals by each UK region of the initial shape file.
UKB_hexa.bng.over <- over(UKB_hexa.bng, input, fn = mean)
# I need to add the number of person per region!
UKB_hexa.bng.over$nb_people <- over(UKB_hexa.bng, input, fn = length)[,1]
# clean format + add the geolabel column + use the good projection
GBR_hexa = SpatialPolygonsDataFrame(UKB_hexa.bng, data=UKB_hexa.bng.over)
GBR_hexa@data$geo_label = UKB_hexa.bng@data$LAD12NM
GBR_hexa = spTransform(GBR_hexa, CRS("+proj=longlat +datum=WGS84 +no_defs"))
# ----------- REGION LARGE ---------------------------
GBR_region_cartogram = cartogram(GBR_region, "nb_people", itermax=1)
incProgress(0.1, detail = "Cartogram region OK")
# ----------- HEXAGONE ---------------------------
GBR_hexa_cartogram = cartogram(GBR_hexa, "nb_people", itermax=1)
save(GBR_region, GBR_region_cartogram, GBR_hexa, GBR_hexa_cartogram, file=output)
output="~/Deskto/UKB_geo_application/DATA/Abdel_data.Rdata"
save(GBR_region, GBR_region_cartogram, GBR_hexa, GBR_hexa_cartogram, file=output)
save(GBR_region, GBR_region_cartogram, GBR_hexa, GBR_hexa_cartogram, file=output)
output="~/Deskto/UKB_geo_application/DATA/Abdel_data.Rdata"
save(GBR_region, GBR_region_cartogram, GBR_hexa, GBR_hexa_cartogram, file=output)
save("toto", file="~/Desktop/toto.RData")
save(GBR_hexa, file="~/Desktop/toto.RData")
save(GBR_region, GBR_hexa, file="~/Desktop/toto.RData")
# 1 - I run this script on Abdel data using these command lines. The result is several spatial polygon data frames I use as input for the application.
# Load the individual matrix saved in part1
# download data from Cluster (/gpfs/gpfs01/polaris/Q0286/UKBiobank/pheno/UKB_geography/for_Yan)
#load("~/Dropbox/QBI/15_ABDEL_UKB_MAP/UKB_geo_application/DATA/Map_data.Rdata")
#input <- read.table("~/Desktop/TEMP_ABDEL/UKB.geowebsite.individual_level.polygenic_scores.100PCs.10kref.csv.gz", header=T, sep=",")
#input=na.omit(input)
#output="~/Deskto/UKB_geo_application/DATA/Abdel_data.Rdata"
#and run the command lines of the function below one by one
# Save objects when I do it on abdel data
save(GBR_region, GBR_region_cartogram, GBR_hexa, GBR_hexa_cartogram, file="~/Deskto/UKB_geo_application/DATA/Abdel_data.Rdata")
output="~/Desktop/UKB_geo_application/DATA/Abdel_data.Rdata"
save(GBR_region, GBR_region_cartogram, GBR_hexa, GBR_hexa_cartogram, file=output)
# Libraries necessary:
suppressWarnings(library(dplyr)) # data manipulation
suppressWarnings(library(lubridate)) # data manipulation
suppressWarnings(library(readxl)) # data manipulation
# Load + build complete address + select interesting fields
demog <- read_excel("../DATA/demog.xlsx") %>%
mutate(address=paste( `Address - Thoroughfare (i.e. Street address)`, `Address - Locality (i.e. City)`, `Address - Postal code`, `Address - Administrative area (i.e. State / Province)`)) %>%
dplyr::select( `Study ID`, `Date of Birth`, `Date of Death`, Gender, `Registration Date`, `Living Status`, address, `Registering Site`)
setwd("~/Desktop/Mapping-patients/PIPELINE")
# Load + build complete address + select interesting fields
demog <- read_excel("../DATA/demog.xlsx") %>%
mutate(address=paste( `Address - Thoroughfare (i.e. Street address)`, `Address - Locality (i.e. City)`, `Address - Postal code`, `Address - Administrative area (i.e. State / Province)`)) %>%
dplyr::select( `Study ID`, `Date of Birth`, `Date of Death`, Gender, `Registration Date`, `Living Status`, address, `Registering Site`)
# Load + build complete address + select interesting fields
demog <- read_excel("../DATA/INIPUT/demog.xlsx") %>%
mutate(address=paste( `Address - Thoroughfare (i.e. Street address)`, `Address - Locality (i.e. City)`, `Address - Postal code`, `Address - Administrative area (i.e. State / Province)`)) %>%
dplyr::select( `Study ID`, `Date of Birth`, `Date of Death`, Gender, `Registration Date`, `Living Status`, address, `Registering Site`)
getwd()
# Load + build complete address + select interesting fields
demog <- read_excel("../DATA/INPUT/demog.xlsx") %>%
mutate(address=paste( `Address - Thoroughfare (i.e. Street address)`, `Address - Locality (i.e. City)`, `Address - Postal code`, `Address - Administrative area (i.e. State / Province)`)) %>%
dplyr::select( `Study ID`, `Date of Birth`, `Date of Death`, Gender, `Registration Date`, `Living Status`, address, `Registering Site`)
# Rename columns
colnames(demog) <- c("id", "birthDate", "deathDate", "gender", "registrationDate", "livingStatus", "address", "state")
# Convert to date format
demog$registrationDate <- gsub(" UTC","",demog$registrationDate) %>% ymd()
demog$birthDate <- demog$birthDate %>% gsub("^[^, ]*, ","", .) %>% gsub(" ","-",.) %>% gsub(",","",.) %>% mdy()
# Load data + select helpful columns
primary <- read_excel("../DATA/INPUT/primary.xlsx") %>%
dplyr::select( `Study ID`, `First Visit Date`, `MND Family History`, `MND Type`, `ALSFRS Calc`, `Date of Onset of MND ALS Symptoms`, `Side of Body`, `Date of Diagnosis` )
# Rename columns
colnames(primary) <- c("id", "firstVisitDate", "familyHistory", "type", "alsfrs", "onsetDate", "side", "diagnosisDate")
# Convert to date format. NOTE -> Some date are lost because of weird formats.
primary$firstVisitDate <- primary$firstVisitDate %>% gsub(" UTC","",.) %>% ymd()
primary$onsetDate <- as.Date(as.numeric(primary$onsetDate), origin = "1899-12-30")
primary$diagnosisDate <- as.Date(as.numeric(primary$diagnosisDate), origin = "1899-12-30")
# Column type needs to be transformed:
primary <- primary %>%
mutate(type = case_when(
type == "Bulbar" ~ "Bulbar",
type == "Unclassified" ~ "Unclassified",
type == "LMN_predominant" ~ "Lower",
type == "UMN_predominant" ~ "Upper",
type == "Classic_ALS" ~ "Classic",
TRUE ~ "Other"
)
)
# Column side needs to be transformed:
primary <- primary %>%
mutate(side = case_when(
side == "RHS" ~ "Right",
side == "LHS" ~ "Left",
side == "LHS, RHS" ~ "Both",
TRUE ~ "Unknown"
)
)
output <- merge(demog , primary, by.x="id", by.y="id", all.y=FALSE)
# What is the age at diagnosis?
output <- output %>%
mutate(ageAtDiagnosis = diagnosisDate - birthDate) %>%
mutate(ageAtDiagnosis = case_when(
ageAtDiagnosis < 14600 ~ "<40",
ageAtDiagnosis >= 14600 & ageAtDiagnosis < 18250 ~ "40-50",
ageAtDiagnosis >= 18250 & ageAtDiagnosis < 21900 ~ "50-60",
ageAtDiagnosis >= 21900 ~ ">60",
TRUE ~ "Unknown"
)
)
# Load subsequent data + select helpful columns
sub <- read_excel("../DATA/INPUT/subsequent.xlsx") %>%
dplyr::select( `Study ID`, `Subsequent Visit Date`, `MND Type`, `ALSFRS Calc`)
# Rename columns
colnames(sub) <- c("id", "subsequentVisitDate", "type", "alsfrs")
# Convert to date format. NOTE -> Some date are lost because of weird formats.
sub$subsequentVisitDate <- sub$subsequentVisitDate %>% gsub(" UTC","",.) %>% ymd()
# Normalize labels
sub <- sub %>%
mutate(type = case_when(
type == "Bulbar" ~ "Bulbar",
type == "Unclassified" ~ "Unclassified",
type == "LMN_predominant" ~ "Lower",
type == "UMN_predominant" ~ "Upper",
type == "Classic_ALS" ~ "Classic",
TRUE ~ "Other"
)
)
# List of patient IDs
allIds <- output$id %>% unique()
# Update the MND type column.
for (i in allIds){
# subset of the subsequent dataset for this patient and this variable + take the last value
last <- sub %>%
filter(id==i) %>%       # keep this patient
dplyr::select(id,subsequentVisitDate,type)  %>%       # we just need 3 columns
drop_na() %>%     #remove missing data
arrange(subsequentVisitDate) %>%      # sort by data
tail(1) %>%       # take into account the most recent visit only
select(type)
# If I have a new value (last is not NA), I replace it in the initial dataset
if(nrow(last)==1){
last <- as.character(last)
output <- output %>%
mutate(type = replace(type, id==i, last))
}
}
# Update the alsfrs column.
for (i in allIds){
# subset of the subsequent dataset for this patient and this variable + take the last value
last <- sub %>%
filter(id==i) %>%       # keep this patient
dplyr::select(id,subsequentVisitDate,alsfrs)  %>%       # we just need 3 columns
drop_na() %>%     #remove missing data
arrange(subsequentVisitDate) %>%      # sort by data
tail(1) %>%       # take into account the most recent visit only
select(alsfrs)
# If I have a new value (last is not NA), I replace it in the initial dataset
if(nrow(last)==1){
last <- as.numeric(last)
output <- output %>%
mutate(alsfrs = replace(alsfrs, id==i, last))
}
}
save(output, file = "../DATA/OUTPT/mergedData.Rdata")
# Update the alsfrs column.
for (i in allIds){
# subset of the subsequent dataset for this patient and this variable + take the last value
last <- sub %>%
filter(id==i) %>%       # keep this patient
dplyr::select(id,subsequentVisitDate,alsfrs)  %>%       # we just need 3 columns
drop_na() %>%     #remove missing data
arrange(subsequentVisitDate) %>%      # sort by data
tail(1) %>%       # take into account the most recent visit only
select(alsfrs)
# If I have a new value (last is not NA), I replace it in the initial dataset
if(nrow(last)==1){
last <- as.numeric(last)
output <- output %>%
mutate(alsfrs = replace(alsfrs, id==i, last))
}
}
save(output, file = "../DATA/OUTPT/mergedData.Rdata")
save(output, file = "../DATA/OUTPUT/mergedData.Rdata")
setwd("~/Desktop/Mapping-patients/PIPELINE")
# Libraries necessary:
suppressWarnings(library(dplyr)) # data manipulation
suppressWarnings(library(opencage)) # geocoding
suppressWarnings(library(jsonlite)) # json output
suppressWarnings(library(dplyr)) # data manipulation
suppressWarnings(library(opencage)) # geocoding
suppressWarnings(library(jsonlite)) # json output
# Load the list of adresses to geocode
load("../DATA/OUTPUT/mergedData.Rdata")
input <- output
cat(paste(nrow(input), "addresses in the input file", "\n"))
# Load the list of adresses we already have geocoded
load("../DATA/adress_with_gps.RData")
# Load the list of adresses we already have geocoded
load("../DATA/OUTPUT/adress_with_gps.RData")
cat(paste(nrow(data), "addresses are already geolocalized. But perhaps not the same as the one we need", "\n"))
# List of adresses to geocode?
toGeocode <- input %>%
filter(! address %in% data$address)
cat(paste(nrow(toGeocode), "addresses still need to be geolocalized", "\n"))
toGeocode = toGeocode %>% head(100)
# A function that return the GPS coordinates of an adress:
geocode <- function(address){
address <- as.character(address)
res <- opencage_forward(placename = address, key="aa789601867b48d6a0625233e786d7e1", limit=1)$res %>%
dplyr::select(geometry.lat, geometry.lng)
output <- data.frame(address=address, lat=res$geometry.lat, lon=res$geometry.lng)
return(output)
}
# Use this function to geocode all the necessary adresses:
addresses <- as.vector(toGeocode$address)
i <- 0
dataWithGeo <- suppressWarnings(
lapply(addresses, function(address) {
i <<- i+1 ;
print(paste("geocoding: ",i, " / ", length(addresses) )) ;
return( geocode(address) )
})  %>%
bind_rows() %>%
data.frame()
)
cat(paste(nrow(dataWithGeo), "addresses have successfully been geolocalized", "\n"))
# Add these new adresses to the original file that contains GPS coordinates
data <- rbind(data, dataWithGeo)
save(data, file="../DATA/adress_with_gps.RData")
cat("\nGeocoding part of the pipeline has been successfull")
# Now merge all the geolocated adresses we have with the initial file
completeInfo <- merge(input, data, by.x="address", by.y="address", all.x=FALSE, all.y=FALSE)
# ALL
completeInfo <- completeInfo %>% filter(!is.na(lat))
tosave <- paste("marker = ", toJSON(completeInfo))
fileConn <- file("../DATA/data.js")
writeLines(tosave, fileConn)
setwd("/Users/y.holtz/Desktop/ABDEL_DATA")
setwd("~/Desktop/ABDEL_DATA")
# Lat-Long + PCs + traits + traits.residual
input <- read.table("UKB.geowebsite.individual_level.polygenic_scores.100PCs.10kref.REVISION.csv", header=T, sep=",", nrows=100)
input=na.omit(input)
# Load map data
load("~/Desktop/UKB_geo_application/DATA/Map_data.Rdata")
output=getwd()
input
colnames(input)
# Geospatial object (=map boundaries + value of each region):
load("DATA/Abdel_data.Rdata")
setwd("/Users/yan.holtz/Desktop/UKB_geo_application")
# Geospatial object (=map boundaries + value of each region):
load("DATA/Abdel_data.Rdata")
# Spatial Autocorrelation values:
load("DATA/Spatial_Autocor.Rdata")
# I transform it in a reactive value
react_values <- reactiveValues(moran_df = moran_data)
ls()
head(GBR_region@data)
colnames(head(GBR_region@data))
